{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64a49e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using devices: [] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Found 10872 images belonging to 2 classes.\n",
      "Found 2330 images belonging to 2 classes.\n",
      "Found 2330 images belonging to 2 classes.\n",
      "Checkpoints found: ['model_checkpoint_lantana_cucoo_epoch_01.keras', 'model_checkpoint_lantana_cucoo_epoch_02.keras', 'model_checkpoint_lantana_cucoo_epoch_03.keras', 'model_checkpoint_lantana_cucoo_epoch_04.keras', 'model_checkpoint_lantana_cucoo_epoch_05.keras', 'model_checkpoint_lantana_cucoo_epoch_06.keras', 'model_checkpoint_lantana_cucoo_epoch_07.keras', 'model_checkpoint_lantana_cucoo_epoch_08.keras', 'model_checkpoint_lantana_cucoo_epoch_09.keras', 'model_checkpoint_lantana_cucoo_epoch_10.keras', 'model_checkpoint_lantana_cucoo_epoch_11.keras', 'model_checkpoint_lantana_cucoo_epoch_12.keras', 'model_checkpoint_lantana_cucoo_epoch_13.keras', 'model_checkpoint_lantana_cucoo_epoch_14.keras', 'model_checkpoint_lantana_cucoo_epoch_15.keras']\n",
      "Resuming from epoch 15\n",
      "🔍 Running Cuckoo Search to find best learning rate...\n",
      "[CS Iter 1/5] Best fitness = 0.8750\n",
      "[CS Iter 2/5] Best fitness = 0.8750\n",
      "[CS Iter 3/5] Best fitness = 0.8750\n",
      "[CS Iter 4/5] Best fitness = 0.8750\n",
      "[CS Iter 5/5] Best fitness = 0.8750\n",
      "✅ Best LR found: 0.000884 with validation accuracy 0.8750\n",
      "🚀 Starting Phase 3: lr=1e-06, epochs=5, flags=['all']\n",
      "Epoch 16/20\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14s/step - accuracy: 0.9114 - loss: 0.5697 \n",
      "Epoch 16: saving model to ./checkpoints_lantana_cucoo\\model_checkpoint_lantana_cucoo_epoch_16.keras\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20279s\u001b[0m 15s/step - accuracy: 0.9114 - loss: 0.5696 - val_accuracy: 0.9790 - val_loss: 0.0924\n",
      "Epoch 17/20\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.9505 - loss: 0.2865 \n",
      "Epoch 17: saving model to ./checkpoints_lantana_cucoo\\model_checkpoint_lantana_cucoo_epoch_17.keras\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15024s\u001b[0m 11s/step - accuracy: 0.9505 - loss: 0.2865 - val_accuracy: 0.9790 - val_loss: 0.1061\n",
      "Epoch 18/20\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9808 - loss: 0.1356\n",
      "Epoch 18: saving model to ./checkpoints_lantana_cucoo\\model_checkpoint_lantana_cucoo_epoch_18.keras\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13581s\u001b[0m 10s/step - accuracy: 0.9808 - loss: 0.1356 - val_accuracy: 0.9931 - val_loss: 0.0402\n",
      "Epoch 19/20\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9869 - loss: 0.0681\n",
      "Epoch 19: saving model to ./checkpoints_lantana_cucoo\\model_checkpoint_lantana_cucoo_epoch_19.keras\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13364s\u001b[0m 10s/step - accuracy: 0.9869 - loss: 0.0681 - val_accuracy: 0.9914 - val_loss: 0.0325\n",
      "Epoch 20/20\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9939 - loss: 0.0294\n",
      "Epoch 20: saving model to ./checkpoints_lantana_cucoo\\model_checkpoint_lantana_cucoo_epoch_20.keras\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13082s\u001b[0m 10s/step - accuracy: 0.9939 - loss: 0.0294 - val_accuracy: 0.9910 - val_loss: 0.0335\n",
      "\u001b[1m1359/1359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3566s\u001b[0m 3s/step\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 3s/step\n",
      "Training Accuracy: 0.5000\n",
      "Training Precision: 0.4939\n",
      "Training Recall: 0.4994\n",
      "Training F1-score: 0.4967\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Force TensorFlow to run on CPU'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19, DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set precision globally\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "print(\"Using devices:\", tf.config.get_visible_devices('GPU'), tf.config.get_visible_devices('CPU'))\n",
    "\n",
    "def clear_memory():\n",
    "    K.clear_session()\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# ——— CHECKPOINT UTILITY ———\n",
    "def get_latest_checkpoint(dir_path):\n",
    "    files = [f for f in os.listdir(dir_path) if f.startswith(\"model_checkpoint_lantana_cucoo_epoch_\")]\n",
    "    print(\"Checkpoints found:\", files)\n",
    "    if not files:\n",
    "        return None, 0\n",
    "    epochs = [int(re.search(r'epoch_(\\d+)', f).group(1)) for f in files if re.search(r'epoch_(\\d+)', f)]\n",
    "    idx = max(range(len(epochs)), key=lambda i: epochs[i])\n",
    "    return os.path.join(dir_path, files[idx]), epochs[idx]\n",
    "\n",
    "# ——— USER SETTINGS ———\n",
    "selected_optimizer = 'adam'\n",
    "train_dir      = 'C:/Users/HP/Desktop/lantana_images/lantana_images/train'\n",
    "validation_dir = 'C:/Users/HP/Desktop/lantana_images/lantana_images/val'\n",
    "test_dir       = 'C:/Users/HP/Desktop/lantana_images/lantana_images/test'\n",
    "checkpoint_dir = './checkpoints_lantana_cucoo'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint_lantana_cucoo_epoch_{epoch:02d}.keras')\n",
    "\n",
    "# ——— DATA GENERATORS ———\n",
    "batch_size = 8\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = datagen.flow_from_directory(train_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "val_gen   = datagen.flow_from_directory(validation_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "test_gen  = datagen.flow_from_directory(test_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "\n",
    "# ——— MODEL UTILITIES ———\n",
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_layers(model, mode):\n",
    "    if mode == 'all':\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "    elif mode == 'last5':\n",
    "        for layer in model.layers[-5:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(224,224,3))\n",
    "    vgg = VGG19(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    dn  = DenseNet121(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    freeze_all(vgg)\n",
    "    freeze_all(dn)\n",
    "\n",
    "    x1 = GlobalAveragePooling2D()(vgg.output)\n",
    "    x2 = GlobalAveragePooling2D()(dn.output)\n",
    "    x  = Concatenate()([x1, x2])\n",
    "    x  = Dense(256, activation='relu')(x)\n",
    "    out= Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "# ——— EVALUATION FUNCTION FOR CSO ———\n",
    "def evaluate_lr(lr_val):\n",
    "    lr = float(lr_val[0]) if isinstance(lr_val, (list, np.ndarray)) else float(lr_val)\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=1, steps_per_epoch=2, validation_steps=1, verbose=0)\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    clear_memory()\n",
    "    return -val_acc\n",
    "\n",
    "class CuckooSearch:\n",
    "    def __init__(self, objective_function, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=5):\n",
    "        self.f = objective_function\n",
    "        self.n = n\n",
    "        self.pa = pa\n",
    "        self.alpha = alpha\n",
    "        self.lb = np.array(lower_bound)\n",
    "        self.ub = np.array(upper_bound)\n",
    "        self.max_iter = max_iter\n",
    "        self.d = len(lower_bound)\n",
    "\n",
    "    def levy_flight(self):\n",
    "        from scipy.special import gamma\n",
    "        beta = 1.5\n",
    "        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n",
    "        u = np.random.randn(self.d) * sigma\n",
    "        v = np.random.randn(self.d)\n",
    "        step = u / np.abs(v)**(1 / beta)\n",
    "        return step\n",
    "\n",
    "    def search(self):\n",
    "        nests = np.random.uniform(self.lb, self.ub, size=(self.n, self.d))\n",
    "        fitness = np.array([self.f(nest) for nest in nests])\n",
    "        best_idx = np.argmin(fitness)\n",
    "        best_nest = nests[best_idx].copy()\n",
    "        best_fitness = fitness[best_idx]\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.n):\n",
    "                step = self.alpha * self.levy_flight()\n",
    "                new_nest = nests[i] + step * (nests[i] - best_nest)\n",
    "                new_nest = np.clip(new_nest, self.lb, self.ub)\n",
    "                new_fit = self.f(new_nest)\n",
    "                if new_fit < fitness[i]:\n",
    "                    nests[i] = new_nest\n",
    "                    fitness[i] = new_fit\n",
    "                    if new_fit < best_fitness:\n",
    "                        best_nest = new_nest\n",
    "                        best_fitness = new_fit\n",
    "\n",
    "            for i in range(self.n):\n",
    "                if random.random() < self.pa:\n",
    "                    nests[i] = np.random.uniform(self.lb, self.ub, self.d)\n",
    "                    fitness[i] = self.f(nests[i])\n",
    "                    if fitness[i] < best_fitness:\n",
    "                        best_nest = nests[i]\n",
    "                        best_fitness = fitness[i]\n",
    "\n",
    "            print(f\"[CS Iter {t+1}/{self.max_iter}] Best fitness = {-best_fitness:.4f}\")\n",
    "\n",
    "        return best_nest, best_fitness\n",
    "\n",
    "def run_cuckoo_search():\n",
    "    print(\"🔍 Running Cuckoo Search to find best learning rate...\")\n",
    "    cs = CuckooSearch(evaluate_lr, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=5)\n",
    "    best_nest, best_score = cs.search()\n",
    "    best_lr = float(best_nest[0])\n",
    "    print(f\"✅ Best LR found: {best_lr:.6f} with validation accuracy {-best_score:.4f}\")\n",
    "    return best_lr\n",
    "\n",
    "# ——— OPTIMIZER FACTORY ———\n",
    "def get_opt(name, lr):\n",
    "    if name == 'adamw':\n",
    "        return tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=1e-5)\n",
    "    elif name == 'nadam':\n",
    "        return tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    else:\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# ——— LOAD FROM CHECKPOINT IF AVAILABLE ———\n",
    "latest_ckpt, last_epoch = get_latest_checkpoint(checkpoint_dir)\n",
    "if latest_ckpt and os.path.exists(latest_ckpt):\n",
    "    model = load_model(latest_ckpt, compile=False)\n",
    "    print(f\"Resuming from epoch {last_epoch}\")\n",
    "    model.compile(optimizer=get_opt(selected_optimizer, 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    model = build_model()\n",
    "    last_epoch = 0\n",
    "    print(\"Starting fresh training\")\n",
    "\n",
    "ckpt_cb = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)\n",
    "\n",
    "# ——— TRAINING PHASES ———\n",
    "lr_phase_0 = run_cuckoo_search()\n",
    "\n",
    "phases = [\n",
    "    (lr_phase_0, 10, []),\n",
    "    (1e-5, 5, ['last5']),\n",
    "    (1e-6, 5, ['all']),\n",
    "]\n",
    "\n",
    "histories = []\n",
    "\n",
    "for idx, (lr, epochs, flags) in enumerate(phases):\n",
    "    phase_start_epoch = sum(p[1] for p in phases[:idx])\n",
    "    phase_end_epoch = phase_start_epoch + epochs\n",
    "    if last_epoch >= phase_end_epoch:\n",
    "        continue\n",
    "\n",
    "    print(f\"🚀 Starting Phase {idx+1}: lr={lr}, epochs={epochs}, flags={flags}\")\n",
    "\n",
    "    if 'all' in flags:\n",
    "        unfreeze_layers(model, 'all')\n",
    "    elif 'last5' in flags:\n",
    "        unfreeze_layers(model, 'last5')\n",
    "\n",
    "    model.compile(optimizer=get_opt(selected_optimizer, lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=phase_end_epoch,\n",
    "        initial_epoch=last_epoch,\n",
    "        callbacks=[ckpt_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    histories.append(history)\n",
    "    last_epoch = phase_end_epoch\n",
    "\n",
    "# ——— TRAINING AND VALIDATION ACCURACY, PRECISION, RECALL, F1 SCORE ———\n",
    "def evaluate_model(model, gen):\n",
    "    y_true = gen.classes\n",
    "    y_pred = (model.predict(gen, verbose=1) > 0.5).astype('int32')\n",
    "    \n",
    "    accuracy = (y_true == y_pred).mean()\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(model, train_gen)\n",
    "val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(model, val_gen)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Training F1-score: {train_f1:.4f}\")\n",
    "print(val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229ad2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999668441120669\n"
     ]
    }
   ],
   "source": [
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818fb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
