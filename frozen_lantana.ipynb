{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ececb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using devices: [] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "# Force TensorFlow to run on CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "# Disable XLA, as it's GPU-focused\n",
    "os.environ['TF_XLA_FLAGS'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19, DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Ensure mixed precision uses float32 globally on CPU\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "print(\"Using devices:\", tf.config.get_visible_devices('GPU'), tf.config.get_visible_devices('CPU'))\n",
    "\n",
    "def clear_memory():\n",
    "    K.clear_session()\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# â€”â€”â€” CHECKPOINT UTIL â€”â€”â€”\n",
    "def get_latest_checkpoint(dir_path):\n",
    "    files = [f for f in os.listdir(dir_path) if f.startswith(\"model_checkpoint_amla_cucoo_epoch_\")]\n",
    "    print(\"Checkpoints found:\", files)\n",
    "    if not files:\n",
    "        return None, 0\n",
    "    epochs = [int(re.search(r'epoch_(\\d+)', f).group(1)) for f in files if re.search(r'epoch_(\\d+)', f)]\n",
    "    idx = max(range(len(epochs)), key=lambda i: epochs[i])\n",
    "    return os.path.join(dir_path, files[idx]), epochs[idx]\n",
    "\n",
    "# â€”â€”â€” USER SETTINGS â€”â€”â€”\n",
    "selected_optimizer = 'adam'\n",
    "train_dir      = './amla_images/train'\n",
    "validation_dir = './amla_images/val'\n",
    "test_dir       = './amla_images/test'\n",
    "checkpoint_dir = './checkpoints_amla_cucoo'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint_amla_cucoo_epoch_{epoch:02d}.keras')\n",
    "\n",
    "# â€”â€”â€” DATA GENERATORS â€”â€”â€”\n",
    "batch_size = 2\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = datagen.flow_from_directory(train_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "val_gen   = datagen.flow_from_directory(validation_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "test_gen  = datagen.flow_from_directory(test_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "\n",
    "# â€”â€”â€” MODEL UTILITIES â€”â€”â€”\n",
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_layers(model, mode):\n",
    "    if mode == 'all':\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "    elif mode == 'last5':\n",
    "        for layer in model.layers[-5:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(224,224,3))\n",
    "    vgg = VGG19(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    dn  = DenseNet121(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    freeze_all(vgg)\n",
    "    freeze_all(dn)\n",
    "\n",
    "    x1 = GlobalAveragePooling2D()(vgg.output)\n",
    "    x2 = GlobalAveragePooling2D()(dn.output)\n",
    "    x  = Concatenate()([x1, x2])\n",
    "    x  = Dense(256, activation='relu')(x)\n",
    "    out= Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "# â€”â€”â€” EVALUATION FUNCTION FOR CSO â€”â€”â€”\n",
    "def evaluate_lr(lr_val):\n",
    "    lr = float(lr_val[0]) if isinstance(lr_val, (list, np.ndarray)) else float(lr_val)\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=1, steps_per_epoch=2, validation_steps=1, verbose=0)\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    clear_memory()\n",
    "    return -val_acc\n",
    "\n",
    "class CuckooSearch:\n",
    "    def init(self, objective_function, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=10):\n",
    "        self.f = objective_function\n",
    "        self.n = n\n",
    "        self.pa = pa\n",
    "        self.alpha = alpha\n",
    "        self.lb = np.array(lower_bound)\n",
    "        self.ub = np.array(upper_bound)\n",
    "        self.max_iter = max_iter\n",
    "        self.d = len(lower_bound)\n",
    "\n",
    "    def levy_flight(self):\n",
    "        from scipy.special import gamma\n",
    "        beta = 1.5\n",
    "        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))(1 / beta)\n",
    "        u = np.random.randn(self.d) * sigma\n",
    "        v = np.random.randn(self.d)\n",
    "        step = u / np.abs(v)(1 / beta)\n",
    "        return step\n",
    "\n",
    "    def search(self):\n",
    "        nests = np.random.uniform(self.lb, self.ub, size=(self.n, self.d))\n",
    "        fitness = np.array([self.f(nest) for nest in nests])\n",
    "        best_idx = np.argmin(fitness)\n",
    "        best_nest = nests[best_idx].copy()\n",
    "        best_fitness = fitness[best_idx]\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.n):\n",
    "                step = self.alpha * self.levy_flight()\n",
    "                new_nest = nests[i] + step * (nests[i] - best_nest)\n",
    "                new_nest = np.clip(new_nest, self.lb, self.ub)\n",
    "                new_fit = self.f(new_nest)\n",
    "                if new_fit < fitness[i]:\n",
    "                    nests[i] = new_nest\n",
    "                    fitness[i] = new_fit\n",
    "                    if new_fit < best_fitness:\n",
    "                        best_nest = new_nest\n",
    "                        best_fitness = new_fit\n",
    "\n",
    "            for i in range(self.n):\n",
    "                if random.random() < self.pa:\n",
    "                    nests[i] = np.random.uniform(self.lb, self.ub, self.d)\n",
    "                    fitness[i] = self.f(nests[i])\n",
    "                    if fitness[i] < best_fitness:\n",
    "                        best_nest = nests[i]\n",
    "                        best_fitness = fitness[i]\n",
    "\n",
    "            print(f\"[CS Iter {t+1}/{self.max_iter}] Best fitness = {-best_fitness:.4f}\")\n",
    "\n",
    "        return best_nest, best_fitness\n",
    "\n",
    "def run_cuckoo_search():\n",
    "    print(\"ðŸ” Running Cuckoo Search to find best learning rate...\")\n",
    "    cs = CuckooSearch(evaluate_lr, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=5)\n",
    "    best_nest, best_score = cs.search()\n",
    "    best_lr = float(best_nest[0])\n",
    "    print(f\"âœ… Best LR found: {best_lr:.6f} with validation accuracy {-best_score:.4f}\")\n",
    "    return best_lr\n",
    "\n",
    "# â€”â€”â€” OPTIMIZER FACTORY â€”â€”â€”\n",
    "def get_opt(name, lr):\n",
    "    if name == 'adamw':\n",
    "        return tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=1e-5)\n",
    "    elif name == 'nadam':\n",
    "        return tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    else:\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# â€”â€”â€” LOAD FROM CHECKPOINT IF AVAILABLE â€”â€”â€”\n",
    "latest_ckpt, last_epoch = get_latest_checkpoint(checkpoint_dir)\n",
    "if latest_ckpt and os.path.exists(latest_ckpt):\n",
    "    model = load_model(latest_ckpt, compile=False)\n",
    "    print(f\"Resuming from epoch {last_epoch}\")\n",
    "    # Recompile after loading\n",
    "    model.compile(optimizer=get_opt(selected_optimizer, 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "    model = build_model()\n",
    "    last_epoch = 0\n",
    "    print(\"Starting fresh training\")\n",
    "\n",
    "ckpt_cb = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)\n",
    "\n",
    "# â€”â€”â€” TRAINING PHASES â€”â€”â€”\n",
    "lr_phase_0 = run_cuckoo_search()\n",
    "\n",
    "phases = [\n",
    "    (lr_phase_0, 10, []),\n",
    "    (1e-5, 5, ['last5']),\n",
    "    (1e-6, 5, ['all']),\n",
    "]\n",
    "\n",
    "histories = []\n",
    "\n",
    "for idx, (lr, epochs, flags) in enumerate(phases):\n",
    "    if last_epoch >= sum(p[1] for p in phases[:idx+1]):\n",
    "        continue\n",
    "\n",
    "    if 'all' in flags:\n",
    "        unfreeze_layers(model, 'all')\n",
    "    elif 'last5' in flags:\n",
    "        unfreeze_layers(model, 'last5')\n",
    "\n",
    "    model.compile(optimizer=get_opt(selected_optimizer, lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c06af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, validation_data=val_gen, epochs=last_epoch + epochs, initial_epoch=last_epoch,\n",
    "                        callbacks=[ckpt_cb], steps_per_epoch=train_gen.samples // batch_size,\n",
    "                        validation_steps=val_gen.samples // batch_size)\n",
    "    histories.append(history)\n",
    "    last_epoch += epochs\n",
    "\n",
    "    if idx < len(phases) - 1:\n",
    "        latest_ckpt, _ = get_latest_checkpoint(checkpoint_dir)\n",
    "        clear_memory()\n",
    "        model = load_model(latest_ckpt, compile=False)\n",
    "        model.compile(optimizer=get_opt(selected_optimizer, lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        print(f\"Cleared session and reloaded model from {latest_ckpt}\")\n",
    "\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
