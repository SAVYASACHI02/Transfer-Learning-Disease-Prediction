{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f28c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/saubhagya/tf-venv/lib/python3.12/site-packages (2.19.0)\n",
      "Collecting mealpy\n",
      "  Downloading mealpy-3.0.1-py3-none-any.whl.metadata (104 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m564.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/saubhagya/tf-venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /home/saubhagya/tf-venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (78.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.7.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from mealpy) (1.15.2)\n",
      "Collecting pandas>=1.2.0 (from mealpy)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opfunu>=1.0.0 (from mealpy)\n",
      "  Downloading opfunu-1.0.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2.0->mealpy)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2.0->mealpy)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/saubhagya/tf-venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading mealpy-3.0.1-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opfunu-1.0.1-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m529.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas, opfunu, mealpy\n",
      "Successfully installed mealpy-3.0.1 opfunu-1.0.1 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow mealpy scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80429d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: ['/physical_device:GPU:0']\n",
      "Found 11124 images belonging to 2 classes.\n",
      "Found 2386 images belonging to 2 classes.\n",
      "Found 2386 images belonging to 2 classes.\n",
      "Checkpoints found: ['model_checkpoint_amla_opta_epoch_20.keras', 'model_checkpoint_amla_opta_epoch_07.keras', 'model_checkpoint_amla_opta_epoch_04.keras', 'model_checkpoint_amla_opta_epoch_02.keras', 'model_checkpoint_amla_opta_epoch_15.keras', 'model_checkpoint_amla_opta_epoch_01.keras', 'model_checkpoint_amla_opta_epoch_13.keras', 'model_checkpoint_amla_opta_epoch_10.keras', 'model_checkpoint_amla_opta_epoch_11.keras', 'model_checkpoint_amla_opta_epoch_09.keras', 'model_checkpoint_amla_opta_epoch_18.keras', 'model_checkpoint_amla_opta_epoch_19.keras', 'model_checkpoint_amla_opta_epoch_05.keras', 'model_checkpoint_amla_opta_epoch_06.keras', 'model_checkpoint_amla_opta_epoch_14.keras', 'model_checkpoint_amla_opta_epoch_16.keras', 'model_checkpoint_amla_opta_epoch_03.keras', 'model_checkpoint_amla_opta_epoch_08.keras', 'model_checkpoint_amla_opta_epoch_12.keras', 'model_checkpoint_amla_opta_epoch_17.keras']\n",
      "Loading from: ./checkpoints_amla_opta/model_checkpoint_amla_opta_epoch_20.keras\n",
      "Resuming from epoch 20\n",
      "ğŸ” Running Cuckoo Search to find best learning rate...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19, DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# â€”â€”â€” GPU & XLA CONFIG â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=0'\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU setup error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU instead.\")\n",
    "\n",
    "def clear_memory():\n",
    "    K.clear_session()\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# â€”â€”â€” CHECKPOINT UTIL â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def get_latest_checkpoint(dir_path):\n",
    "    files = [f for f in os.listdir(dir_path) if f.startswith(\"model_checkpoint_amla_opta_epoch_\")]\n",
    "    print(\"Checkpoints found:\", files)\n",
    "    if not files:\n",
    "        return None, 0\n",
    "    epochs = [int(re.search(r'epoch_(\\d+)', f).group(1)) for f in files if re.search(r'epoch_(\\d+)', f)]\n",
    "    idx = max(range(len(epochs)), key=lambda i: epochs[i])\n",
    "    return os.path.join(dir_path, files[idx]), epochs[idx]\n",
    "\n",
    "# â€”â€”â€” USER SETTINGS â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "selected_optimizer = 'adam'\n",
    "train_dir      = './amla_images/train'\n",
    "validation_dir = './amla_images/val'\n",
    "test_dir       = './amla_images/test'\n",
    "checkpoint_dir = './checkpoints_amla_opta'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint_amla_opta_epoch_{epoch:02d}.keras')\n",
    "\n",
    "# â€”â€”â€” DATA GENERATORS â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "batch_size = 2\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_gen = datagen.flow_from_directory(train_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "val_gen   = datagen.flow_from_directory(validation_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary')\n",
    "test_gen  = datagen.flow_from_directory(test_dir, target_size=(224,224), batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "\n",
    "# â€”â€”â€” MODEL UTILITIES â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def freeze_all(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_layers(model, mode):\n",
    "    if mode == 'all':\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = True\n",
    "    elif mode == 'last5':\n",
    "        for layer in model.layers[-5:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(224,224,3))\n",
    "    vgg = VGG19(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    dn  = DenseNet121(weights='imagenet', include_top=False, input_tensor=inp)\n",
    "    freeze_all(vgg)\n",
    "    freeze_all(dn)\n",
    "\n",
    "    x1 = GlobalAveragePooling2D()(vgg.output)\n",
    "    x2 = GlobalAveragePooling2D()(dn.output)\n",
    "    x  = Concatenate()([x1, x2])\n",
    "    x  = Dense(256, activation='relu')(x)\n",
    "    out= Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    return model\n",
    "\n",
    "# â€”â€”â€” EVALUATION FUNCTION FOR CSO â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def evaluate_lr(lr_val):\n",
    "    lr = float(lr_val[0]) if isinstance(lr_val, (list, np.ndarray)) else float(lr_val)\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    start = time.time()\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=2, steps_per_epoch=3, validation_steps=2, verbose=0)\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    duration = time.time() - start\n",
    "    print(f\"Evaluated lr={lr:.6f} â†’ val_acc={val_acc:.4f} in {duration:.2f}s\")\n",
    "    clear_memory()\n",
    "    return -val_acc\n",
    "\n",
    "class CuckooSearch:\n",
    "    def __init__(self, objective_function, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=10):\n",
    "        self.f = objective_function\n",
    "        self.n = n\n",
    "        self.pa = pa\n",
    "        self.alpha = alpha\n",
    "        self.lb = np.array(lower_bound)\n",
    "        self.ub = np.array(upper_bound)\n",
    "        self.max_iter = max_iter\n",
    "        self.d = len(lower_bound)\n",
    "\n",
    "    def levy_flight(self):\n",
    "        from scipy.special import gamma\n",
    "        beta = 1.5\n",
    "        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n",
    "        u = np.random.randn(self.d) * sigma\n",
    "        v = np.random.randn(self.d)\n",
    "        step = u / np.abs(v)**(1 / beta)\n",
    "        return step\n",
    "\n",
    "    def search(self):\n",
    "        nests = np.random.uniform(self.lb, self.ub, size=(self.n, self.d))\n",
    "        fitness = np.array([self.f(nest) for nest in nests])\n",
    "        best_idx = np.argmin(fitness)\n",
    "        best_nest = nests[best_idx].copy()\n",
    "        best_fitness = fitness[best_idx]\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            for i in range(self.n):\n",
    "                step = self.alpha * self.levy_flight()\n",
    "                new_nest = nests[i] + step * (nests[i] - best_nest)\n",
    "                new_nest = np.clip(new_nest, self.lb, self.ub)\n",
    "                new_fit = self.f(new_nest)\n",
    "                if new_fit < fitness[i]:\n",
    "                    nests[i] = new_nest\n",
    "                    fitness[i] = new_fit\n",
    "                    if new_fit < best_fitness:\n",
    "                        best_nest = new_nest\n",
    "                        best_fitness = new_fit\n",
    "\n",
    "            for i in range(self.n):\n",
    "                if random.random() < self.pa:\n",
    "                    nests[i] = np.random.uniform(self.lb, self.ub, self.d)\n",
    "                    fitness[i] = self.f(nests[i])\n",
    "                    if fitness[i] < best_fitness:\n",
    "                        best_nest = nests[i]\n",
    "                        best_fitness = fitness[i]\n",
    "\n",
    "            print(f\"[CS Iter {t+1}/{self.max_iter}] Best fitness = {-best_fitness:.4f}\")\n",
    "\n",
    "        return best_nest, best_fitness\n",
    "\n",
    "def run_cuckoo_search():\n",
    "    print(\"ğŸ” Running Cuckoo Search to find best learning rate...\")\n",
    "    cs = CuckooSearch(evaluate_lr, n=5, pa=0.25, alpha=0.01, lower_bound=[1e-6], upper_bound=[1e-3], max_iter=5)\n",
    "    best_nest, best_score = cs.search()\n",
    "    best_lr = float(best_nest[0])\n",
    "    print(f\"âœ… Best LR found: {best_lr:.6f} with validation accuracy {-best_score:.4f}\")\n",
    "    return best_lr\n",
    "\n",
    "# â€”â€”â€” OPTIMIZER FACTORY â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def get_opt(name, lr):\n",
    "    if name == 'adamw':\n",
    "        return tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=1e-5)\n",
    "    elif name == 'nadam':\n",
    "        return tf.keras.optimizers.Nadam(learning_rate=lr)\n",
    "    else:\n",
    "        return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# â€”â€”â€” LOAD FROM CHECKPOINT IF AVAILABLE â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "latest_ckpt, last_epoch = get_latest_checkpoint(checkpoint_dir)\n",
    "if latest_ckpt and os.path.exists(latest_ckpt):\n",
    "    print(f\"Loading from: {latest_ckpt}\")\n",
    "    model = load_model(latest_ckpt, compile=False)\n",
    "    print(f\"Resuming from epoch {last_epoch}\")\n",
    "else:\n",
    "    model = build_model()\n",
    "    last_epoch = 0\n",
    "    print(\"Starting fresh training\")\n",
    "\n",
    "ckpt_cb = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)\n",
    "\n",
    "# â€”â€”â€” TRAINING PHASES â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "lr_phase_0 = run_cuckoo_search()\n",
    "\n",
    "phases = [\n",
    "    (lr_phase_0, 10, []),\n",
    "    (1e-5, 5, ['last5']),\n",
    "    (1e-6, 5, ['all']),\n",
    "]\n",
    "\n",
    "histories = []\n",
    "\n",
    "for idx, (lr, epochs, flags) in enumerate(phases):\n",
    "    if last_epoch >= sum(p[1] for p in phases[:idx+1]):\n",
    "        continue\n",
    "\n",
    "    if 'all' in flags:\n",
    "        unfreeze_layers(model, 'all')\n",
    "    elif 'last5' in flags:\n",
    "        unfreeze_layers(model, 'last5')\n",
    "\n",
    "    model.compile(optimizer=get_opt(selected_optimizer, lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=last_epoch + epochs, initial_epoch=last_epoch,\n",
    "                        callbacks=[ckpt_cb], steps_per_epoch=train_gen.samples // batch_size,\n",
    "                        validation_steps=val_gen.samples // batch_size)\n",
    "    histories.append(history)\n",
    "    last_epoch += epochs\n",
    "\n",
    "    if idx < len(phases) - 1:\n",
    "        latest_ckpt, _ = get_latest_checkpoint(checkpoint_dir)\n",
    "        clear_memory()\n",
    "        model = load_model(latest_ckpt, compile=False)\n",
    "        print(f\"Cleared session and reloaded model from {latest_ckpt}\")\n",
    "\n",
    "# â€”â€”â€” PLOT HISTORY â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "plt.figure()\n",
    "for i, h in enumerate(histories):\n",
    "    plt.plot(h.history['accuracy'], label=f'train_acc_phase{i}')\n",
    "    plt.plot(h.history['val_accuracy'], label=f'val_acc_phase{i}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i, h in enumerate(histories):\n",
    "    plt.plot(h.history['loss'], label=f'train_loss_phase{i}')\n",
    "    plt.plot(h.history['val_loss'], label=f'val_loss_phase{i}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# â€”â€”â€” FINAL EVALUATION â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "val_loss, val_acc = model.evaluate(val_gen)\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"Validation â†’ loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
    "print(f\"Test       â†’ loss={test_loss:.4f}, acc={test_acc:.4f}\")\n",
    "\n",
    "test_gen.reset()\n",
    "probs = model.predict(test_gen, steps=test_gen.samples // batch_size + 1).ravel()\n",
    "preds = (probs > 0.5).astype(int)\n",
    "labels = test_gen.classes\n",
    "print(classification_report(labels, preds))\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "fpr, tpr, _ = roc_curve(labels, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"ROC AUC = {roc_auc:.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# â€”â€”â€” FINAL CLEANUP â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d50b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-venv)",
   "language": "python",
   "name": "tf-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
